{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lista3_Fabricio_414900_AM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GweNZLLyMjXu",
        "OEqWVOzeMxsf"
      ],
      "authorship_tag": "ABX9TyOiT5anXKKKQZfign87AOEW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fabriloko/Machine_Learn/blob/main/Lista3_Fabricio_414900_AM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW5V_m1KMJ4a"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier as mlp_c\n",
        "from sklearn.neural_network import MLPRegressor as mlp_r\n",
        "from sklearn.model_selection import RandomizedSearchCV as RandomSearch\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm2NfqGSLtFj"
      },
      "source": [
        "concrete_dataset = np.genfromtxt('/content/concrete.csv',delimiter=',')\n",
        "vowel_dataset = np.genfromtxt('/content/vowel.csv',delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR4lRDPHMbIg"
      },
      "source": [
        "# **Funções Uteis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkyaH2-pMdr3"
      },
      "source": [
        "def MSE(y,y_pred): # Calcula o MSE\n",
        "  return np.mean((y - y_pred)**2)\n",
        "\n",
        "def RMSE(y,y_pred): # Calcula o MSE\n",
        "  return np.sqrt(np.mean((y - y_pred)**2))\n",
        "\n",
        "def MAE(y,y_pred):\n",
        "  return np.mean(np.abs(y - y_pred))\n",
        "\n",
        "def MRE(y, y_pred):\n",
        "  return np.mean((np.abs(y - y_pred) / y))\n",
        "\n",
        "def dividir_treino_teste(dados):\n",
        "  np.random.shuffle(dados)\n",
        "  X_treino = dados[:,:-1][:int(len(dados)*0.8)]\n",
        "  X_teste  = dados[:,:-1][int(len(dados)*0.8):]\n",
        "  y_treino = dados[:,[-1]][:int(len(dados)*0.8)]\n",
        "  y_teste  = dados[:,[-1]][int(len(dados)*0.8):]\n",
        "  return y_treino,y_teste,X_treino, X_teste\n",
        "\n",
        "def make_meshgrid(x, y, steps=300):\n",
        "    x_min, x_max = x.min() - 1, x.max() + 1\n",
        "    y_min, y_max = y.min() - 1, y.max() + 1\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, steps), np.linspace(y_min, y_max, steps))\n",
        "    return xx, yy\n",
        "\n",
        "def plot_contours(ax, clf, xx, yy, colors=['red', 'blue']):\n",
        "    labels = clf(np.c_[ xx.ravel(), yy.ravel() ]).reshape(xx.shape)\n",
        "    out = ax.contourf(xx, yy, labels, levels=len(np.unique(labels))-1, colors=colors, alpha=0.5)    \n",
        "    return out\n",
        "\n",
        "class normalize_01(): #Normalizacao 0 ou 1\n",
        "  def __init__(self, X):\n",
        "    self.min = np.min(X,axis=0)\n",
        "    self.max = np.max(X,axis=0)\n",
        "  def norma(self, X):\n",
        "    return (X - self.min)/(self.max - self.min)\n",
        "  def desnorm(self, X):\n",
        "    return X * (self.max - self.min) + self.min\n",
        "\n",
        "def sig(z): #Funcao Sigmoide\n",
        "  return 1/(1 + np.exp(-z))\n",
        "\n",
        "def TanH(z):\n",
        "  return (np.exp(2 * z) - 1) / (np.exp(2 * z) + 1)\n",
        "\n",
        "def ReLu(z):\n",
        "  return np.maximum(0, z)\n",
        "\n",
        "def Gaussian(x, media, cov):\n",
        "    dim = np.shape(cov)[0]\n",
        "    # Medidas do Determinante da Matriz de Covariancia\n",
        "    covdet = np.linalg.det(cov + np.eye(dim) * 0.000001)\n",
        "    covinv = np.linalg.inv(cov + np.eye(dim) * 0.000001)\n",
        "    xdiff = (x - media).reshape((1, dim))\n",
        "\n",
        "    # Funcao Densidade de Probabilidade\n",
        "    prob = 0.5 * (np.log( 2 * np.pi * np.abs(covdet)) + xdiff @ covinv @ xdiff.T)\n",
        "    return prob\n",
        "\n",
        "#Avaliacao dos Classificadores\n",
        "def metricas(real,pred):\n",
        "  count = 0\n",
        "  verd_posi  = 0 #Verdadeiro Positivos\n",
        "  falso_neg  = 0 #Falsos Negativos\n",
        "  falso_posi = 0 #Falsos Positivos\n",
        "  for i in range(len(pred)):\n",
        "    if pred[i] == real[i]:\n",
        "      count += 1 \n",
        "    if pred[i] == 1 and pred[i] == real[i]:\n",
        "      verd_posi += 1 \n",
        "    if pred[i] == 0 and pred[i] != real[i]:\n",
        "      falso_neg += 1 \n",
        "    if pred[i] == 1 and pred[i] != real[i]:\n",
        "      falso_posi += 1 \n",
        "\n",
        "  acc  = count    / len(pred)\n",
        "  rev  = verd_posi / (verd_posi + falso_neg) \n",
        "  prec = verd_posi / (verd_posi + falso_posi)\n",
        "  F_1 = 2 * (rev * prec)/(rev + prec)\n",
        "\n",
        "  aux = np.array([acc, rev, prec, F_1])\n",
        "  return {\"Acuracia\":acc,'Revocacao': rev, 'Precisao': prec, 'F1_Score': F_1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GweNZLLyMjXu"
      },
      "source": [
        "# **Questão 1:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "21QnSdZMDdEO",
        "outputId": "a0be2ca7-94a1-4dcd-af47-43e112248eb6"
      },
      "source": [
        "def REG_MLP(dados,iteracoes=100):\n",
        "  y_treino, y_teste ,X_treino, X_teste = dividir_treino_teste(dados)\n",
        "\n",
        "  X_normalize = normalize_01(X_treino)\n",
        "  X_treino = X_normalize.norma(X_treino)\n",
        "  X_treino = np.c_[(np.ones(X_treino.shape[0]), X_treino)]\n",
        "  X_teste = np.c_[(np.ones(X_teste.shape[0]), X_teste)]\n",
        "\n",
        "  parametros = {'hidden_layer_sizes': (25, 50, 75, 100),\n",
        "                'learning_rate': ('constant','adaptive'), \n",
        "                'batch_size':(70, 90, 100, 130, 'auto'),\n",
        "                'activation':('tanh','relu')}\n",
        "\n",
        "  Modelo = mlp_r(solver= 'sgd', max_iter= iteracoes, random_state= 0, verbose= False, learning_rate_init= 0.01, \n",
        "                 early_stopping= False, momentum= 0.9, nesterovs_momentum= False, shuffle=False)\n",
        "\n",
        "  #Random Search\n",
        "  Model = RandomSearch(Modelo, parametros, refit= True, cv= 5, verbose= False)\n",
        "\n",
        "  #Resultado do Random Search\n",
        "  Model.fit(X_treino, y_treino.ravel())\n",
        "  mark = pd.DataFrame(Model.cv_results_)\n",
        "  print(f\"Resultados Random Search: \\n{mark[['params','mean_test_score','std_test_score','rank_test_score']].to_markdown()}\")\n",
        "\n",
        "  #Treinando o modelo com os melhores parametros do Random Search\n",
        "  Modelo.set_params(**Model.best_params_)\n",
        "\n",
        "  #Adiquirindo as méticas\n",
        "  Modelo.fit(X_treino, y_treino.ravel())\n",
        "  Treino_Perda = Modelo.loss_curve_\n",
        "  Modelo.fit(X_teste, y_teste.ravel())\n",
        "  Teste_Perda = Modelo.loss_curve_\n",
        "  \n",
        "  return Treino_Perda, Teste_Perda\n",
        "\n",
        "Treino_Perda, Teste_Perda = REG_MLP(concrete_dataset)\n",
        "\n",
        "plt.plot(range(100), Treino_Perda, color= 'orange', label= 'RMSE_Treino')\n",
        "plt.plot(range(100), Teste_Perda, color= 'b', label= 'RMSE_Teste')\n",
        "plt.title(\"RMSE: Treino X Teste\")\n",
        "plt.legend()\n",
        "plt.close()\n",
        "\n",
        "plt.plot(range(100), Treino_Perda, color= 'orange', label= 'MAE_Treino')\n",
        "plt.plot(range(100), Teste_Perda, color= 'b', label= 'MAE_Teste')\n",
        "plt.title(\"MAE: Treino X Teste\")\n",
        "plt.legend()\n",
        "plt.close()\n",
        "\n",
        "plt.plot(range(100), Treino_Perda, color= 'orange', label= 'MRE_Treino')\n",
        "plt.plot(range(100), Teste_Perda, color= 'b', label= 'MRE_Teste')\n",
        "plt.title(\"MRE: Treino X Teste\")\n",
        "plt.legend()\n",
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resultados Random Search: \n",
            "|    | params                                                                                               |   mean_test_score |   std_test_score |   rank_test_score |\n",
            "|---:|:-----------------------------------------------------------------------------------------------------|------------------:|-----------------:|------------------:|\n",
            "|  0 | {'learning_rate': 'adaptive', 'hidden_layer_sizes': 75, 'batch_size': 90, 'activation': 'tanh'}      |          0.860565 |        0.0553827 |                 1 |\n",
            "|  1 | {'learning_rate': 'constant', 'hidden_layer_sizes': 50, 'batch_size': 100, 'activation': 'tanh'}     |          0.842387 |        0.0597935 |                 3 |\n",
            "|  2 | {'learning_rate': 'adaptive', 'hidden_layer_sizes': 75, 'batch_size': 130, 'activation': 'tanh'}     |          0.83925  |        0.0389445 |                 5 |\n",
            "|  3 | {'learning_rate': 'adaptive', 'hidden_layer_sizes': 100, 'batch_size': 90, 'activation': 'tanh'}     |          0.841196 |        0.058178  |                 4 |\n",
            "|  4 | {'learning_rate': 'constant', 'hidden_layer_sizes': 75, 'batch_size': 'auto', 'activation': 'tanh'}  |          0.819352 |        0.0629187 |                 8 |\n",
            "|  5 | {'learning_rate': 'adaptive', 'hidden_layer_sizes': 100, 'batch_size': 'auto', 'activation': 'tanh'} |          0.82992  |        0.0449382 |                 6 |\n",
            "|  6 | {'learning_rate': 'constant', 'hidden_layer_sizes': 75, 'batch_size': 90, 'activation': 'tanh'}      |          0.846277 |        0.0685727 |                 2 |\n",
            "|  7 | {'learning_rate': 'adaptive', 'hidden_layer_sizes': 75, 'batch_size': 100, 'activation': 'relu'}     |          0.783345 |        0.0747776 |                10 |\n",
            "|  8 | {'learning_rate': 'adaptive', 'hidden_layer_sizes': 75, 'batch_size': 90, 'activation': 'relu'}      |          0.795236 |        0.0225951 |                 9 |\n",
            "|  9 | {'learning_rate': 'adaptive', 'hidden_layer_sizes': 50, 'batch_size': 70, 'activation': 'relu'}      |          0.822388 |        0.035079  |                 7 |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-91d0a4f7369e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTreino_Perda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'orange'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'RMSE_Treino'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTeste_Perda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'RMSE_Teste'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RMSE: Treino X Teste\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (95,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEqWVOzeMxsf"
      },
      "source": [
        "# **Questão 2:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXgL3VXiM1sv"
      },
      "source": [
        "def CLA_MLP(dados,iteracoes=1000):\n",
        "  y_treino, y_teste ,X_treino, X_teste = dividir_treino_teste(dados)\n",
        "\n",
        "  X_normalize = normalize_01(X_treino)\n",
        "  X_treino = X_normalize.norma(X_treino)\n",
        "  X_treino = np.c_[(np.ones(X_treino.shape[0]), X_treino)]\n",
        "  X_teste = np.c_[(np.ones(X_teste.shape[0]), X_teste)]\n",
        "\n",
        "  parametros = {'hidden_layer_sizes': (25, 50, 75, 100),\n",
        "                'learning_rate': ('constant','adaptive'), \n",
        "                'batch_size':(70, 90, 100, 130, 'auto'),\n",
        "                'activation':('tanh','relu')}\n",
        "\n",
        "  Modelo = mlp_c(solver= 'sgd', max_iter= iteracoes, random_state= 0, verbose= False, learning_rate_init= 0.01, \n",
        "                 early_stopping= False, momentum= 0.9, nesterovs_momentum= False, shuffle= False)\n",
        "\n",
        "  #Random Search\n",
        "  Model = RandomSearch(Modelo, parametros, refit= True, cv= 5, verbose= False)\n",
        "\n",
        "  #Resultado do Random Search\n",
        "  Model.fit(X_treino, y_treino.ravel())\n",
        "  mark = pd.DataFrame(Model.cv_results_)\n",
        "  print(f\"Resultados Random Search: \\n{mark[['params','mean_test_score','std_test_score','rank_test_score']].to_markdown()}\")\n",
        "\n",
        "  #Treinando o modelo com os melhores parametros do Random Search\n",
        "  Modelo.set_params(**Model.best_params_)\n",
        "\n",
        "  #Adiquirindo as méticas\n",
        "  Modelo.fit(X_treino, y_treino.ravel())\n",
        "  Treino_Perda = Modelo.predict(X_treino)\n",
        "\n",
        "  Modelo.fit(X_teste, y_teste.ravel())\n",
        "  Teste_Perda = Modelo.predict(X_teste)\n",
        "  \n",
        "  return Treino_Perda, Teste_Perda, y_treino, y_teste\n",
        "\n",
        "Treino_Perda, Teste_Perda, y_treino, y_teste = CLA_MLP(vowel_dataset)\n",
        "\n",
        "metr_treino = metricas(y_treino, Treino_Perda)\n",
        "print(f\"Acuracia: {metr_treino['Acuracia']:.2%} \\n\"\n",
        "      f\"Revocacao: {metr_treino['Revocacao']:.2%} \\n\"\n",
        "      f\"Precisao: {metr_treino['Precisao']:.2%} \\n\"\n",
        "      f\"F1_Score: {metr_treino['F1_Score']:.2%} \\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}