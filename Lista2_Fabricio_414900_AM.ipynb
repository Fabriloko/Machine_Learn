{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lista2_Fabricio_414900_AM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yHFlxTQKTMv7",
        "mDU1JUcbFo2u",
        "sHrbjSDsWGMp",
        "jNQIh3M9qHyc",
        "S8TVXJrBqIN1"
      ],
      "authorship_tag": "ABX9TyOWpsd9zscwvVxlwkiaoT2h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fabriloko/Machine_Learn/blob/main/Lista2_Fabricio_414900_AM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtQw-c7Wz3Yo"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URlprRxgTMNW"
      },
      "source": [
        "mama_dataset = np.genfromtxt('/content/breastcancer.csv',delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHFlxTQKTMv7"
      },
      "source": [
        "# **Funções Uteis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhwTvW83T2j_"
      },
      "source": [
        "def MSE(y,y_pred): # Calcula o MSE\n",
        "  return np.mean((y - y_pred)**2)\n",
        "\n",
        "def RMSE(y,y_pred): # Calcula o MSE\n",
        "  return np.mean(np.sqrt((y - y_pred)**2))\n",
        "\n",
        "def dividir_treino_teste(dados):\n",
        "  np.random.shuffle(dados)\n",
        "  X_treino = dados[:,:-1][:int(len(dados)*0.7)]\n",
        "  X_teste  = dados[:,:-1][int(len(dados)*0.7):]\n",
        "  y_treino = dados[:,[-1]][:int(len(dados)*0.7)]\n",
        "  y_teste  = dados[:,[-1]][int(len(dados)*0.7):]\n",
        "  return y_treino,y_teste,X_treino, X_teste\n",
        "\n",
        "def make_meshgrid(x, y, steps=300):\n",
        "    x_min, x_max = x.min() - 1, x.max() + 1\n",
        "    y_min, y_max = y.min() - 1, y.max() + 1\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, steps), np.linspace(y_min, y_max, steps))\n",
        "    return xx, yy\n",
        "\n",
        "def plot_contours(ax, clf, xx, yy, colors=['red', 'blue']):\n",
        "    labels = clf(np.c_[ xx.ravel(), yy.ravel() ]).reshape(xx.shape)\n",
        "    out = ax.contourf(xx, yy, labels, levels=len(np.unique(labels))-1, colors=colors, alpha=0.5)    \n",
        "    return out\n",
        "\n",
        "class normalize_01(): #Normalizacao 0 ou 1\n",
        "  def __init__(self, X):\n",
        "    self.min = np.min(X,axis=0)\n",
        "    self.max = np.max(X,axis=0)\n",
        "  def norma(self, X):\n",
        "    return (X - self.min)/(self.max - self.min)\n",
        "  def desnorm(self, X):\n",
        "    return X * (self.max - self.min) + self.min\n",
        "\n",
        "def sig(z): #Funcao Sigmoide\n",
        "  return 1/(1 + np.exp(-z))\n",
        "\n",
        "def Gaussian(x, media, cov):\n",
        "    dim = np.shape(cov)[0]\n",
        "    # Medidas do Determinante da Matriz de Covariancia\n",
        "    covdet = np.linalg.det(cov + np.eye(dim) * 0.000001)\n",
        "    covinv = np.linalg.inv(cov + np.eye(dim) * 0.000001)\n",
        "    xdiff = (x - media).reshape((1, dim))\n",
        "\n",
        "    # Funcao Densidade de Probabilidade\n",
        "    prob = 0.5 * (np.log( 2 * np.pi * np.abs(covdet)) + xdiff @ covinv @ xdiff.T)\n",
        "    return prob\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA51smFEV_Er"
      },
      "source": [
        "# **Questão 1:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDU1JUcbFo2u"
      },
      "source": [
        "## **Avaliacao dos Classificadores**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM-0cZfLckFv"
      },
      "source": [
        "#Avaliacao dos Classificadores\n",
        "def metricas(real,pred):\n",
        "  count = 0\n",
        "  verd_posi  = 0 #Verdadeiro Positivos\n",
        "  falso_neg  = 0 #Falsos Negativos\n",
        "  falso_posi = 0 #Falsos Positivos\n",
        "  for i in range(len(pred)):\n",
        "    if pred[i] == real[i]:\n",
        "      count += 1 \n",
        "    if pred[i] == 1 and pred[i] == real[i]:\n",
        "      verd_posi += 1 \n",
        "    if pred[i] == 0 and pred[i] != real[i]:\n",
        "      falso_neg += 1 \n",
        "    if pred[i] == 1 and pred[i] != real[i]:\n",
        "      falso_posi += 1 \n",
        "\n",
        "  acc  = count    / len(pred)\n",
        "  rev  = verd_posi / (verd_posi + falso_neg) \n",
        "  prec = verd_posi / (verd_posi + falso_posi)\n",
        "  F_1 = 2 * (rev * prec)/(rev + prec)\n",
        "\n",
        "  aux = np.array([acc, rev, prec, F_1])\n",
        "  return [acc, rev, prec, F_1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHrbjSDsWGMp"
      },
      "source": [
        "## **Regressão Logistica**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAaz3tdBJd31",
        "outputId": "18f5d7a4-a3c2-4692-8a2d-d6225f700afb"
      },
      "source": [
        "def RegLogi(dados): # Regressao Logistica adaptada a partir do SGD  \n",
        "  w_SGD = np.zeros((1,dados.shape[1])) # Vetor de parametros iniciais\n",
        "  alpha = 0.1 # Valor de Alpha\n",
        "  iteracoes = 100 # Numero maximo de iteracoes\n",
        "  metr = [] #Array de metricas\n",
        "\n",
        "  kf = KFold(n_splits=10,shuffle=True)\n",
        "  for treino, teste in kf.split(dados):  \n",
        "    treino = dados[treino] \n",
        "    teste = dados[teste]\n",
        "    \n",
        "    X_treino = treino[:,:-1]\n",
        "    X_teste = teste[:,:-1]\n",
        "    y_treino = treino[:,[-1]] \n",
        "    y_teste = teste[:,[-1]]\n",
        "\n",
        "    normalize_X = normalize_01(X_treino)\n",
        "    X_treino = normalize_X.norma(X_treino) \n",
        "    X_teste  = normalize_X.norma(X_teste) \n",
        "    X_treino = np.c_[np.ones(X_treino.shape[0]),X_treino]\n",
        "    X_teste  = np.c_[np.ones(X_teste.shape[0]),X_teste]\n",
        "\n",
        "    for i in range(iteracoes): #Laco de atualizacao\n",
        "      for j in np.random.permutation(X_treino.shape[0]): #Permutacao aleatoria das entradas\n",
        "        y_pred = sig(w_SGD @ X_treino[[j]].T) #Saida estimada para y_i\n",
        "        error = y_treino[j] - y_pred #Atualizacao do Erro para y_i\n",
        "        w_SGD = w_SGD + alpha * error * X_treino[[j]] # Atualizacao do vetor de parametros   \n",
        "    \n",
        "    y_pred = np.round(sig(X_teste @ w_SGD.T)) #Considerando uma probabilidade de 50% para positivo \n",
        "    metr.append(metricas(y_teste,y_pred))\n",
        "  return metr\n",
        "\n",
        "metr_RL = RegLogi(mama_dataset)\n",
        "\n",
        "acc  = []\n",
        "rev  = [] \n",
        "prec = []\n",
        "F_1  = []\n",
        "\n",
        "for i in range(10):\n",
        "  acc.append(metr_RL[i][0])\n",
        "  rev.append(metr_RL[i][1])\n",
        "  prec.append(metr_RL[i][2])\n",
        "  F_1.append(metr_RL[i][3])\n",
        "\n",
        "print(\"Acuracia: Média = \",np.mean(acc),\", Desvio Padrão = \",np.std(acc))\n",
        "print(\"Revocação: Média = \",np.mean(rev),\", Desvio Padrão = \",np.std(rev))\n",
        "print(\"Precisão: Média = \",np.mean(prec),\", Desvio Padrão = \",np.std(prec))\n",
        "print(\"F-1 score: Média = \",np.mean(F_1),\", Desvio Padrão = \",np.std(F_1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acuracia: Média =  0.9842105263157894 , Desvio Padrão =  0.012280701754385968\n",
            "Revocação: Média =  0.9913078149920256 , Desvio Padrão =  0.013317384370015936\n",
            "Precisão: Média =  0.9833836098541981 , Desvio Padrão =  0.02221330545064317\n",
            "F-1 score: Média =  0.9870842192633237 , Desvio Padrão =  0.010035232778626293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNQIh3M9qHyc"
      },
      "source": [
        "## **Análise do discriminante Gaussiano**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yWLFRB3qe7x",
        "outputId": "477da35a-0303-4c4d-c557-ee07d681f203"
      },
      "source": [
        "def DiscGauss(dados):\n",
        "  metr = [] #Array de metricas\n",
        "\n",
        "  kf = KFold(n_splits=10,shuffle=True)\n",
        "  for treino, teste in kf.split(dados):  \n",
        "    treino = dados[treino] \n",
        "    teste = dados[teste]\n",
        "    \n",
        "    X_treino = treino[:,:-1]\n",
        "    X_teste = teste[:,:-1]\n",
        "    y_treino = treino[:,[-1]] \n",
        "    y_teste = teste[:,[-1]]\n",
        "    \n",
        "    # Vetores de Quantidades. Classes(C1 e C0) e Resultados(Positivos / Negativos)\n",
        "    C1 = 0 \n",
        "    C0 = 0\n",
        "    postivos = []\n",
        "    negetivos = []\n",
        "    \n",
        "    # Contando e Agrupando os resultados positivos e negativos\n",
        "    for (x,y) in zip(X_treino, y_treino):\n",
        "        if y == 1: # Verdadeiros Positivos\n",
        "            C1 += 1\n",
        "            postivos.append(list(x))\n",
        "        else:      # Verdadeiros Negativos\n",
        "            C0 += 1\n",
        "            negetivos.append(list(x))\n",
        "\n",
        "    # Estimando a probabilidade dos exemplos positivos e negativos\n",
        "    lin, col = np.shape(X_treino)\n",
        "    priori_C1 = C1/lin            #Probabiliade da Classe 1 \n",
        "    priori_C0 = 1 - priori_C1       #Probabiliade da Classe 0\n",
        "\n",
        "    # Estimando os vetores de media dos exemplos positivos e negativos\n",
        "    postivos = np.array(postivos)\n",
        "    negetivos = np.array(negetivos)\n",
        "    media_positivos = np.sum(postivos, axis= 0) / C1\n",
        "    media_negetivos = np.sum(negetivos, axis= 0) / C0\n",
        "\n",
        "    # Estimando a matriz de covariancia\n",
        "    delta_positivos = postivos - media_positivos\n",
        "    delta_negativos = negetivos - media_negetivos\n",
        "    sigma = []\n",
        "    for delta in delta_positivos:\n",
        "        delta = delta.reshape(1, col)\n",
        "        aux = delta.T @ delta\n",
        "        sigma.append(aux)\n",
        "    for delta in delta_negativos:\n",
        "        delta = delta.reshape(1, col)\n",
        "        aux = delta.T @ delta\n",
        "        sigma.append(aux)\n",
        "    sigma = np.array(sigma)\n",
        "    sigma = np.sum(sigma, axis = 0) / (lin - 1) \n",
        "    media_positivos = media_positivos.reshape(1, col)\n",
        "    media_negetivos = media_negetivos.reshape(1, col)\n",
        "\n",
        "    #Prevendo novos resultados\n",
        "    y_pred = []\n",
        "    for d in X_teste:\n",
        "        prob_positivo = np.log(priori_C1) - Gaussian(d, media_positivos, sigma)\n",
        "        prob_negativo = np.log(priori_C0) - Gaussian(d, media_negetivos, sigma)\n",
        "        if prob_positivo >= prob_negativo:\n",
        "            y_pred.append(1)\n",
        "        else:\n",
        "            y_pred.append(0)\n",
        "    metr.append(metricas(y_teste, y_pred))\n",
        "  return metr\n",
        "\n",
        "metr_GDA = DiscGauss(mama_dataset)\n",
        "\n",
        "acc  = []\n",
        "rev  = [] \n",
        "prec = []\n",
        "F_1  = []\n",
        "\n",
        "for i in range(10):\n",
        "  acc.append(metr_GDA[i][0])\n",
        "  rev.append(metr_GDA[i][1])\n",
        "  prec.append(metr_GDA[i][2])\n",
        "  F_1.append(metr_GDA[i][3])\n",
        "\n",
        "print(\"Acuracia: Média = \",np.mean(acc),\", Desvio Padrão = \",np.std(acc))\n",
        "print(\"Revocação: Média = \",np.mean(rev),\", Desvio Padrão = \",np.std(rev))\n",
        "print(\"Precisão: Média = \",np.mean(prec),\", Desvio Padrão = \",np.std(prec))\n",
        "print(\"F-1 score: Média = \",np.mean(F_1),\", Desvio Padrão = \",np.std(F_1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acuracia: Média =  0.9560776942355889 , Desvio Padrão =  0.01794749161648426\n",
            "Revocação: Média =  0.9937254901960785 , Desvio Padrão =  0.012579619554780737\n",
            "Precisão: Média =  0.9396905292570927 , Desvio Padrão =  0.02917379553481384\n",
            "F-1 score: Média =  0.9655874775139079 , Desvio Padrão =  0.013564137300766912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8TVXJrBqIN1"
      },
      "source": [
        "## **Naive Bayes Gaussiano**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74o96WAbqdyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bbe5a8b-42b6-48b1-a15e-324fdc33cb7c"
      },
      "source": [
        "def NaiveBayesGauss(dados):\n",
        "  metr = [] #Array de metricas\n",
        "\n",
        "  kf = KFold(n_splits=10,shuffle=True)\n",
        "  for treino, teste in kf.split(dados):  \n",
        "    treino = dados[treino] \n",
        "    teste = dados[teste]\n",
        "    \n",
        "    X_treino = treino[:,:-1]\n",
        "    X_teste = teste[:,:-1]\n",
        "    y_treino = treino[:,[-1]] \n",
        "    y_teste = teste[:,[-1]]\n",
        "    \n",
        "    # Vetores de Quantidades. Classes(C1 e C0) e Resultados(Positivos / Negativos)\n",
        "    C1 = 0 \n",
        "    C0 = 0\n",
        "    postivos = []\n",
        "    negetivos = []\n",
        "    \n",
        "    # Contando e Agrupando os resultados positivos e negativos\n",
        "    for (x,y) in zip(X_treino, y_treino):\n",
        "        if y == 1: # Verdadeiros Positivos\n",
        "            C1 += 1\n",
        "            postivos.append(list(x))\n",
        "        else:      # Verdadeiros Negativos\n",
        "            C0 += 1\n",
        "            negetivos.append(list(x))\n",
        "\n",
        "    # Estimando a probabilidade dos exemplos positivos e negativos\n",
        "    lin, col = np.shape(X_treino)\n",
        "    priori_C1 = C1/lin            #Probabiliade da Classe 1 \n",
        "    priori_C0 = 1 - priori_C1       #Probabiliade da Classe 0\n",
        "\n",
        "    # Estimando os vetores de media dos exemplos positivos e negativos\n",
        "    postivos = np.array(postivos)\n",
        "    negetivos = np.array(negetivos)\n",
        "    media_positivos = np.sum(postivos, axis= 0) / C1\n",
        "    media_negetivos = np.sum(negetivos, axis= 0) / C0\n",
        "\n",
        "    # Estimando a matriz de covariancia\n",
        "    delta_positivos = postivos - media_positivos\n",
        "    delta_negativos = negetivos - media_negetivos\n",
        "    sigma = []\n",
        "    for delta in delta_positivos:\n",
        "        delta = delta.reshape(1, col)\n",
        "        aux = delta.T @ delta\n",
        "        sigma.append(aux)\n",
        "    for delta in delta_negativos:\n",
        "        delta = delta.reshape(1, col)\n",
        "        aux = delta.T @ delta\n",
        "        sigma.append(aux)\n",
        "    sigma = np.array(sigma)\n",
        "    sigma = np.sum(sigma, axis = 0) / (lin - 1) \n",
        "    media_positivos = media_positivos.reshape(1, col)\n",
        "    media_negetivos = media_negetivos.reshape(1, col)\n",
        "    sigma = sigma * np.eye(np.shape(sigma)[0]) # Matriz de Covariancia Diagonal\n",
        "    \n",
        "    #Prevendo novos resultados\n",
        "    y_pred = []\n",
        "    for d in X_teste:\n",
        "        prob_positivo = np.log(priori_C1) - Gaussian(d, media_positivos, sigma)\n",
        "        prob_negativo = np.log(priori_C0) - Gaussian(d, media_negetivos, sigma)\n",
        "        if prob_positivo >= prob_negativo:\n",
        "            y_pred.append(1)\n",
        "        else:\n",
        "            y_pred.append(0)\n",
        "    metr.append(metricas(y_teste, y_pred))\n",
        "  return metr\n",
        "\n",
        "metr_NBG = NaiveBayesGauss(mama_dataset)\n",
        "\n",
        "acc  = []\n",
        "rev  = [] \n",
        "prec = []\n",
        "F_1  = []\n",
        "\n",
        "for i in range(10):\n",
        "  acc.append(metr_NBG[i][0])\n",
        "  rev.append(metr_NBG[i][1])\n",
        "  prec.append(metr_NBG[i][2])\n",
        "  F_1.append(metr_NBG[i][3])\n",
        "\n",
        "print(\"Acuracia: Média = \",np.mean(acc),\", Desvio Padrão = \",np.std(acc))\n",
        "print(\"Revocação: Média = \",np.mean(rev),\", Desvio Padrão = \",np.std(rev))\n",
        "print(\"Precisão: Média = \",np.mean(prec),\", Desvio Padrão = \",np.std(prec))\n",
        "print(\"F-1 score: Média = \",np.mean(F_1),\", Desvio Padrão = \",np.std(F_1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acuracia: Média =  0.9384398496240601 , Desvio Padrão =  0.03712300263925304\n",
            "Revocação: Média =  0.9775721256971257 , Desvio Padrão =  0.026996259004650584\n",
            "Precisão: Média =  0.9295702329912856 , Desvio Padrão =  0.049644007092126435\n",
            "F-1 score: Média =  0.9520565760197416 , Desvio Padrão =  0.028356606952434135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3lxIUXlkSGR"
      },
      "source": [
        "## **KNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfYny7Dj6Pig",
        "outputId": "06a93842-eebb-4f49-8f34-9f3b8b061798"
      },
      "source": [
        "def KNN(dados, k = 3):\n",
        "  metr = []\n",
        "\n",
        "  kf = KFold(n_splits=10,shuffle=True)\n",
        "  for treino, teste in kf.split(dados):  \n",
        "    treino = dados[treino] \n",
        "    teste = dados[teste]\n",
        "    \n",
        "    X_treino = treino[:,:-1]\n",
        "    X_teste = teste[:,:-1]\n",
        "    y_treino = treino[:,[-1]] \n",
        "    y_teste = teste[:,[-1]]\n",
        "\n",
        "    y_pred = []\n",
        "    for x in X_teste:\n",
        "      distancia = np.sqrt(np.sum(X_treino - x, axis= 1) ** 2)\n",
        "      aux = np.round(np.mean(y_treino[np.argpartition(distancia, k)][:k]))\n",
        "      y_pred.append(aux)\n",
        "\n",
        "    metr.append(metricas(y_teste, y_pred))\n",
        "  return metr\n",
        "\n",
        "metr_KNN = KNN(mama_dataset)\n",
        "\n",
        "acc  = []\n",
        "rev  = [] \n",
        "prec = []\n",
        "F_1  = []\n",
        "\n",
        "for i in range(10):\n",
        "  acc.append(metr_KNN[i][0])\n",
        "  rev.append(metr_KNN[i][1])\n",
        "  prec.append(metr_KNN[i][2])\n",
        "  F_1.append(metr_KNN[i][3])\n",
        "\n",
        "print(\"Acuracia: Média = \",np.mean(acc),\", Desvio Padrão = \",np.std(acc))\n",
        "print(\"Revocação: Média = \",np.mean(rev),\", Desvio Padrão = \",np.std(rev))\n",
        "print(\"Precisão: Média = \",np.mean(prec),\", Desvio Padrão = \",np.std(prec))\n",
        "print(\"F-1 score: Média = \",np.mean(F_1),\", Desvio Padrão = \",np.std(F_1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acuracia: Média =  0.8804824561403508 , Desvio Padrão =  0.04761600743823725\n",
            "Revocação: Média =  0.9063752835509916 , Desvio Padrão =  0.05723989090763634\n",
            "Precisão: Média =  0.9059442196864216 , Desvio Padrão =  0.060145803841531266\n",
            "F-1 score: Média =  0.9036347002941122 , Desvio Padrão =  0.03558505552856812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKs5tdbSkXlC"
      },
      "source": [
        "## **Árvore de decisão**"
      ]
    }
  ]
}